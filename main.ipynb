{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview explaining what is in each notebook, the conclusions, and how it contributes to total:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``n1_initial_eda.ipynb``\n",
    "\n",
    "This notebook is meant to give an initial insight into the dataset. We load the data and perform an initial explorative data analysis procedure. \n",
    "\n",
    "Conclusions:\n",
    "- Depending on the columns used for the model, we need to find a suitable way to impute data, because there are quite some missing values.\n",
    "- There is a lot of categorical data with high number of categories. So this needs to be dealt with appropriately. Either by means of dimensionality reduction, or by means of proper feature selection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``n2_comparing_nn_with_rf.ipynb``\n",
    "\n",
    "The goal of this notebook is to create models that incorporate all columns. We want to see how the different models deal with this.\n",
    "\n",
    "- The conclusion is that the RandomForestClassifier model holds up well against the neural network approach. It is, however, slightly worse than the neural network. 97.1% accuracy on the test set versus 98.0% accuracy For this reason, the in the next notebook (`n3`_text_to_vector), we will look into ways to improve the neural network by improving the word embedding of the `DescrizioneRiga` text column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``n3_text_to_vector.ipynb``\n",
    "\n",
    "The goal of this notebook is to try and improve the neural network. To do this, the main focus improving the way in which we vectorize the text. As this was an essential part of the course, we felt that we wanted to dive into text embedding to see if we could extract relevant information from this text. For this we use three methods:\n",
    "\n",
    "- TFIDF with english word lemmatizer\n",
    "- TFIDF with italian word lemmatizer\n",
    "- Transformer word embedding, to obtain more of the actual meaning of the text\n",
    "\n",
    "The conclusion is that none of these methods strongly improved the predictions that could be made using the text. It seems that the text column is just not as informative or relevant as we had assumed. Therefore, in the next notebook `n4`_refining_features we investigate opportunities in refining the number of input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``n4_refining_features.ipynb``\n",
    "\n",
    "The goal of this notebook is to investigate the consequences of refining the number of features. First we limit the features to all numerical features and the set of categorical features for which we have a clear explanation in the dataset description. We figured that these are the most crucial features. We preprocess these according to the correct way. We find out that we do not have to impute any values, we only have to delete approximately a 1000 rows for missing values in the `B` column (both NaNs and 0 values for which there is no explanation). We then train a RandomForrestClassifier and a DecisionTreeClassifier. We found out using this that the performance barely decreased when we used these simpler models with a far smaller number of input features. Furthermore, this analysis let us investigate the feature importance. This allows us to refine the number of features even further. \n",
    "\n",
    "- Conclusions: despite the earlier reduction in the number of features, we see that the Random Forest model and even a simpler Decision Tree still hold up very well. We find that we can achieve a accuracy of 97.3% with these models. This is very good compared to the 98.6% which was achieved with all features. Furthermore, the feature importances show that we can still reduce the number of features even further. \n",
    "\n",
    "In the following **Notebook `5` - all final models.ipynb** we provide all models with this newly refined small set of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``n5_all_final_models.ipynb``\n",
    "\n",
    "The goal of this notebook is to analyse the performance of the three different models trained on the reduced set of features. These are models with still very good performance despite the strong reduction in the number of features.\n",
    "\n",
    "Conclusions: \n",
    "\n",
    "- All models still perform quite well. \n",
    "- It must however be noted that the neural network performs worse than the random forest and decision tree models. \n",
    "- Since these more standard machine learning approaches do not only perform better but are also more interpretable these approaches are preferred. \n",
    "- Since the performance of the decision tree and the random forest model are very similar, we choose the simplest model. Therefore the decision tree is the preferred model for the task.\n",
    "\n",
    "As a result of this final comparison, we choose to implement the decision tree model into our interactive user interface. This can be used in the `user_interface.py`. This dashboard can also be ran from the `main.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``user_interface.py``\n",
    "\n",
    "User interface can be ran, by simply running this python file. It uses some functions from the ``ui_backend.py`` file, the assests used by the UI were created using the ``ui_asset_creator.py`` file. A local host with a dashboard is then created (e.g. http://127.0.0.1:8050/). In this dashboard you can use the model. For this user interface we implemented the small Decision Tree. Of course, other models could also be implemented in a similar way. If we were to implement the Neural Network and Random Forest, we could also show the predicted class probabilities. To use the dashboard, you should use the file selector button to load the `assets/ui_demo/UI_data_50_cases_from_test_set` file. This then loads into the table. By clicking any cell in the row, you then predict the VAT exemption code for this row of data. This prediction appears together with the actual VAT examption code at the bottom of the table. It also displays the columns that were used for the prediction in the table below. Hopefully, you can have some fun with it, and it shows how the model could be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
