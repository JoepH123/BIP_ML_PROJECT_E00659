{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "In order to get started with this repository, it is important to setup a correct virtual environment, and download the necessary dependencies of this project. This can for example be done by creating a virtual environment and installing all dependencies using ``pip install -r requirements.text``. When you have done this, you can run the different files of the project. Note that to run notebooks using the virtual environments, it is important to use the correct kernel. \n",
    "\n",
    "To create a virtual environment:\n",
    "- go to command line\n",
    "- ``pip install virtualenv``\n",
    "- ``cd path/to/your/project`` (navigate to project)\n",
    "- ``virtualenv myenv`` (create virtual environment)\n",
    "- ``myenv\\Scripts\\activate`` or ``source myenv/bin/activat`` (activate environment windows or MacOS/Linux respectively)\n",
    "- ``pip install -r requirements.txt`` (install all dependencies of this project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repository Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview explaining what is in each notebook, the conclusions, and how it contributes to total:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``n1_initial_eda.ipynb``\n",
    "\n",
    "This notebook is meant to give an initial insight into the dataset. We load the data and perform an initial explorative data analysis procedure. \n",
    "\n",
    "Conclusions:\n",
    "- Depending on the columns used for the model, we need to find a suitable way to impute data, because there are quite some missing values.\n",
    "- There is a lot of categorical data with high number of categories. So this needs to be dealt with appropriately. Either by means of dimensionality reduction, or by means of proper feature selection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``n2_comparing_nn_with_rf.ipynb``\n",
    "\n",
    "The goal of this notebook is to create models that incorporate all columns. We want to see how the different models deal with this.\n",
    "\n",
    "- The conclusion is that the RandomForestClassifier model holds up well against the neural network approach. It is, however, slightly worse than the neural network. 97.5% accuracy on the test set versus 98.0% accuracy For this reason, the in the next notebook (**`n3`_text_to_vector**), we will look into ways to improve the neural network by improving the word embedding of the `DescrizioneRiga` text column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``n3_text_to_vector.ipynb``\n",
    "\n",
    "The goal of this notebook is to try and improve the neural network. To do this, the main focus is on improving the way in which we vectorize the text. As this was an essential part of the course, we felt that we wanted to dive into text embedding to see if we could extract relevant information from this text. For this we use three methods:\n",
    "\n",
    "- TFIDF with english word lemmatizer\n",
    "- TFIDF with italian word lemmatizer\n",
    "- Transformer word embedding, to obtain more of the actual meaning of the text\n",
    "\n",
    "The conclusion is that none of these methods strongly improved the predictions that could be made using the text. It seems that the text column is just not as informative or relevant as we had assumed. Therefore, in the next notebook **`n4`_refining_features** we investigate opportunities in refining the number of input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``n4_refining_features.ipynb``\n",
    "\n",
    "The goal of this notebook is to investigate the consequences of refining the number of features. First, we limit the features to all numerical features and the set of categorical features for which we have a clear explanation in the dataset description. We figured that if these features are more elaborately explained, these are the most crucial features. We preprocess all features as follows: numerical features are scaled and categorical features are one-hot encoded using dummy variables. We find out that we do not have to impute any values, we only have to delete approximately a 1000 rows for missing values in the `B` column (both NaNs and 0-values for which there is no explanation). We then train a RandomForrestClassifier and a DecisionTreeClassifier. We found out using this that the performance barely decreased when we used these simpler models, with a far smaller number of input features. Furthermore, this analysis let us investigate the feature importance. This allows us to refine the number of features even further. \n",
    "\n",
    "- Conclusions: despite the earlier reduction in the number of features, we see that the Random Forest model and even a simpler Decision Tree still hold up very well. We find that we can achieve a accuracy of 97.3% with these models. This is very good compared to the 97.5% which was achieved with all features. Furthermore, the feature importances show that we can still reduce the number of features even further. \n",
    "\n",
    "In the following **Notebook `5` - all final models.ipynb** we provide all models with this newly refined small set of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``n5_all_final_models.ipynb``\n",
    "\n",
    "The goal of this notebook is to analyse the performance of the three different models trained on the reduced set of features. These are models with, still, a very good performance despite the strong reduction in the number of features.\n",
    "\n",
    "Conclusions: \n",
    "\n",
    "- All models still perform quite well. \n",
    "- It must however be noted that the neural network performs worse than the random forest and decision tree models. It seems to have suffered most significantly from the reduction in the number of featuers. \n",
    "- Since these more classical machine learning approaches do not only perform better but are also more interpretable these approaches are preferred. \n",
    "- Since the performance of the decision tree and the random forest model are very similar, we choose the simplest model. Therefore the decision tree is the preferred model for the task.\n",
    "\n",
    "As a result of this final comparison, we choose to implement the decision tree model into our interactive user interface. This can be used in the `user_interface.py`. In the next section, we explain how the dashboard works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``user_interface.py``\n",
    "\n",
    "User interface can be ran, by simply running this python file. It uses some functions from the ``ui_backend.py`` file, the assests used by the UI were created using the ``ui_asset_creator.py`` file. This does not have to be ran, however, as we included the assets in the repository. A local host with a dashboard is then created (e.g. http://127.0.0.1:8050/). In this dashboard you can use the model. For this user interface we implemented the Decision Tree with low dimensionality. Of course, other models could also be implemented in a similar way. If we were to implement the Neural Network and Random Forest, we could also show the predicted class probabilities. To use the dashboard, you should use the file selector button to load the `assets/ui_demo/UI_data_50_cases_from_test_set` file. This then loads into the table. By clicking any cell in a row of the table, you then predict the VAT exemption code for this row of data. This prediction appears together with the actual VAT examption code at the bottom of the table. It also displays the columns that were used for the prediction in the table below. Hopefully, you can have some fun with it, and it gives an indication of how the model could be used. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
